#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
í™˜ ë¦¬ìŠ¤í¬ í—·ì§€ ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ ë©”ì¸ ì‹¤í–‰ íŒŒì¼
ë°ì´í„° í†µí•©, í•™ìŠµ, í‰ê°€ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
"""

import argparse
import os
import sys
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

# í•„ìš”í•œ ëª¨ë“ˆë“¤ import
try:
    from data_integration import DataIntegrator
    from hedge_environment import HedgeEnvironment
    from hedge_agent import HedgeAgent
    print("âœ… ëª¨ë“  ëª¨ë“ˆ import ì„±ê³µ")
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    print("í˜„ì¬ ë””ë ‰í† ë¦¬ì— í•„ìš”í•œ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    sys.exit(1)

def setup_environment():
    """í™˜ê²½ ì„¤ì •"""
    print("ğŸ”§ í™˜ê²½ ì„¤ì • ì¤‘...")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = current_dir / "results"
    output_dir.mkdir(exist_ok=True)
    
    # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    model_dir = current_dir / "models"
    model_dir.mkdir(exist_ok=True)
    
    # í†µí•© ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
    integrated_data_dir = current_dir / "integrated_data"
    integrated_data_dir.mkdir(exist_ok=True)
    
    print(f"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ")
    print(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    print(f"   ëª¨ë¸ ë””ë ‰í† ë¦¬: {model_dir}")
    print(f"   í†µí•© ë°ì´í„° ë””ë ‰í† ë¦¬: {integrated_data_dir}")
    
    return output_dir, model_dir, integrated_data_dir

def run_data_integration():
    """ë°ì´í„° í†µí•© ì‹¤í–‰"""
    print("\n" + "="*60)
    print("ğŸ“Š 1ë‹¨ê³„: ë°ì´í„° í†µí•©")
    print("="*60)
    
    try:
        integrator = DataIntegrator()
        data_path = integrator.run_integration()
        return data_path
    except Exception as e:
        print(f"âŒ ë°ì´í„° í†µí•© ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

def run_training(data_path: str, output_dir: Path, model_dir: Path, 
                num_episodes: int = 1000, eval_interval: int = 100):
    """ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ í•™ìŠµ ì‹¤í–‰"""
    print("\n" + "="*60)
    print("ğŸ¯ 2ë‹¨ê³„: ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ í•™ìŠµ")
    print("="*60)
    
    try:
        # í™˜ê²½ ìƒì„±
        print("ğŸŒ ê°•í™”í•™ìŠµ í™˜ê²½ ìƒì„± ì¤‘...")
        env = HedgeEnvironment(
            data_path=data_path,
            initial_capital=1000000.0,  # 100ë§Œ ë‹¬ëŸ¬
            max_hedge_ratio=1.0,        # ìµœëŒ€ í—·ì§€ ë¹„ìœ¨ 100%
            transaction_cost=0.001,     # ê±°ë˜ ë¹„ìš© 0.1%
            risk_free_rate=0.02         # ë¬´ìœ„í—˜ ìˆ˜ìµë¥  2%
        )
        
        # ì—ì´ì „íŠ¸ ìƒì„±
        print("ğŸ¤– ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ ìƒì„± ì¤‘...")
        state_dim = env.observation_space.shape[0]
        action_dim = env.action_space.n
        
        agent = HedgeAgent(
            state_dim=state_dim,
            action_dim=action_dim,
            learning_rate=3e-4,
            gamma=0.99,
            gae_lambda=0.95,
            clip_ratio=0.2,
            value_loss_coef=0.5,
            entropy_coef=0.01,
            max_grad_norm=0.5
        )
        
        print(f"ğŸ“Š í™˜ê²½ ì •ë³´:")
        print(f"   ìƒíƒœ ì°¨ì›: {state_dim}")
        print(f"   ì•¡ì…˜ ì°¨ì›: {action_dim}")
        print(f"   ìµœëŒ€ ìŠ¤í…: {env.max_steps}")
        
        # í•™ìŠµ ì‹¤í–‰
        print(f"\nğŸš€ í•™ìŠµ ì‹œì‘: {num_episodes} ì—í”¼ì†Œë“œ")
        training_history = agent.train(env, num_episodes, eval_interval)
        
        # í•™ìŠµ ê²°ê³¼ ì‹œê°í™”
        print("\nğŸ“Š í•™ìŠµ ê²°ê³¼ ì‹œê°í™” ì¤‘...")
        plot_path = output_dir / "training_history.png"
        agent.plot_training_history(save_path=str(plot_path))
        
        # ëª¨ë¸ ì €ì¥
        print("\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
        model_path = model_dir / "hedge_agent_model.pth"
        agent.save_model(str(model_path))
        
        return agent, training_history
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def run_evaluation(agent: HedgeAgent, data_path: str, output_dir: Path, 
                  num_eval_episodes: int = 100):
    """ì—ì´ì „íŠ¸ í‰ê°€ ì‹¤í–‰"""
    print("\n" + "="*60)
    print("ğŸ” 3ë‹¨ê³„: ì—ì´ì „íŠ¸ í‰ê°€")
    print("="*60)
    
    try:
        # í‰ê°€ìš© í™˜ê²½ ìƒì„±
        print("ğŸŒ í‰ê°€ìš© í™˜ê²½ ìƒì„± ì¤‘...")
        eval_env = HedgeEnvironment(
            data_path=data_path,
            initial_capital=1000000.0,
            max_hedge_ratio=1.0,
            transaction_cost=0.001,
            risk_free_rate=0.02
        )
        
        # ì—ì´ì „íŠ¸ í‰ê°€
        evaluation_results = agent.evaluate(eval_env, num_eval_episodes)
        
        # í‰ê°€ ê²°ê³¼ ì €ì¥
        print("\nğŸ’¾ í‰ê°€ ê²°ê³¼ ì €ì¥ ì¤‘...")
        eval_path = output_dir / "evaluation_results.txt"
        
        with open(eval_path, 'w', encoding='utf-8') as f:
            f.write("=== í™˜ ë¦¬ìŠ¤í¬ í—·ì§€ ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ í‰ê°€ ê²°ê³¼ ===\n\n")
            f.write(f"í‰ê°€ ì—í”¼ì†Œë“œ ìˆ˜: {num_eval_episodes}\n\n")
            
            f.write("=== ì„±ëŠ¥ ì§€í‘œ ===\n")
            f.write(f"í‰ê·  ë³´ìƒ: {evaluation_results['mean_reward']:.4f} Â± {evaluation_results['std_reward']:.4f}\n")
            f.write(f"í‰ê·  ì—í”¼ì†Œë“œ ê¸¸ì´: {evaluation_results['mean_length']:.2f}\n")
            f.write(f"í‰ê·  ìµœì¢… ìë³¸: ${evaluation_results['mean_final_capital']:,.2f}\n")
            f.write(f"ìµœì¢… ìë³¸ í‘œì¤€í¸ì°¨: ${evaluation_results['std_final_capital']:,.2f}\n")
            f.write(f"ìƒ¤í”„ ë¹„ìœ¨: {evaluation_results['sharpe_ratio']:.4f}\n")
        
        print(f"âœ… í‰ê°€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {eval_path}")
        
        return evaluation_results
        
    except Exception as e:
        print(f"âŒ í‰ê°€ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

def run_backtesting(agent: HedgeAgent, data_path: str, output_dir: Path):
    """ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰"""
    print("\n" + "="*60)
    print("ğŸ“ˆ 4ë‹¨ê³„: ë°±í…ŒìŠ¤íŒ…")
    print("="*60)
    
    try:
        # ë°±í…ŒìŠ¤íŒ…ìš© í™˜ê²½ ìƒì„±
        print("ğŸŒ ë°±í…ŒìŠ¤íŒ…ìš© í™˜ê²½ ìƒì„± ì¤‘...")
        backtest_env = HedgeEnvironment(
            data_path=data_path,
            initial_capital=1000000.0,
            max_hedge_ratio=1.0,
            transaction_cost=0.001,
            risk_free_rate=0.02
        )
        
        # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
        print("ğŸ“Š ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ ì¤‘...")
        state, info = backtest_env.reset()
        
        backtest_results = {
            'dates': [],
            'capitals': [],
            'hedge_ratios': [],
            'positions': [],
            'actions': [],
            'rewards': []
        }
        
        step = 0
        while True:
            # ì•¡ì…˜ ì„ íƒ (í‰ê°€ ëª¨ë“œ)
            action = agent.select_action(state, training=False)
            
            # í™˜ê²½ì—ì„œ ìŠ¤í… ì‹¤í–‰
            next_state, reward, done, truncated, info = backtest_env.step(action)
            
            # ê²°ê³¼ ì €ì¥
            if step < len(backtest_env.data):
                current_date = backtest_env.data.iloc[step]['date']
                backtest_results['dates'].append(current_date)
                backtest_results['capitals'].append(info['current_capital'])
                backtest_results['hedge_ratios'].append(info['hedge_ratio'])
                backtest_results['positions'].append(info['position'])
                backtest_results['actions'].append(action)
                backtest_results['rewards'].append(reward)
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            state = next_state
            step += 1
            
            if done or truncated:
                break
        
        # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ì‹œê°í™”
        print("ğŸ“Š ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ì‹œê°í™” ì¤‘...")
        import matplotlib.pyplot as plt
        import pandas as pd
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # ìë³¸ê¸ˆ ë³€í™”
        axes[0, 0].plot(backtest_results['dates'], backtest_results['capitals'])
        axes[0, 0].set_title('ìë³¸ê¸ˆ ë³€í™”')
        axes[0, 0].set_xlabel('ë‚ ì§œ')
        axes[0, 0].set_ylabel('ìë³¸ê¸ˆ ($)')
        axes[0, 0].grid(True, alpha=0.3)
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # í—·ì§€ ë¹„ìœ¨ ë³€í™”
        axes[0, 1].plot(backtest_results['dates'], backtest_results['hedge_ratios'])
        axes[0, 1].set_title('í—·ì§€ ë¹„ìœ¨ ë³€í™”')
        axes[0, 1].set_xlabel('ë‚ ì§œ')
        axes[0, 1].set_ylabel('í—·ì§€ ë¹„ìœ¨')
        axes[0, 1].grid(True, alpha=0.3)
        axes[0, 1].tick_params(axis='x', rotation=45)
        
        # ì•¡ì…˜ ë¶„í¬
        action_counts = pd.Series(backtest_results['actions']).value_counts()
        axes[1, 0].bar(range(len(action_counts)), action_counts.values)
        axes[1, 0].set_title('ì•¡ì…˜ ë¶„í¬')
        axes[1, 0].set_xlabel('ì•¡ì…˜')
        axes[1, 0].set_ylabel('ë¹ˆë„')
        axes[1, 0].set_xticks(range(len(action_counts)))
        axes[1, 0].set_xticklabels([f'A{i}' for i in action_counts.index])
        
        # ë³´ìƒ ëˆ„ì 
        cumulative_rewards = np.cumsum(backtest_results['rewards'])
        axes[1, 1].plot(backtest_results['dates'], cumulative_rewards)
        axes[1, 1].set_title('ëˆ„ì  ë³´ìƒ')
        axes[1, 1].set_xlabel('ë‚ ì§œ')
        axes[1, 1].set_ylabel('ëˆ„ì  ë³´ìƒ')
        axes[1, 1].grid(True, alpha=0.3)
        axes[1, 1].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ì €ì¥
        backtest_plot_path = output_dir / "backtest_results.png"
        plt.savefig(backtest_plot_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ì €ì¥: {backtest_plot_path}")
        
        # ë°±í…ŒìŠ¤íŒ… ë°ì´í„° ì €ì¥
        backtest_df = pd.DataFrame(backtest_results)
        backtest_csv_path = output_dir / "backtest_results.csv"
        backtest_df.to_csv(backtest_csv_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ ë°±í…ŒìŠ¤íŒ… ë°ì´í„° ì €ì¥: {backtest_csv_path}")
        
        plt.show()
        
        return backtest_results
        
    except Exception as e:
        print(f"âŒ ë°±í…ŒìŠ¤íŒ… ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

def run_test():
    """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*60)
    print("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰")
    print("="*60)
    
    try:
        # 1. ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
        print("ğŸ“¦ ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸...")
        from data_integration import DataIntegrator
        from hedge_environment import HedgeEnvironment
        from hedge_agent import HedgeAgent
        print("âœ… ëª¨ë“  ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ")
        
        # 2. ë°ì´í„° í†µí•© í…ŒìŠ¤íŠ¸
        print("\nğŸ“Š ë°ì´í„° í†µí•© í…ŒìŠ¤íŠ¸...")
        integrator = DataIntegrator()
        integrated = integrator.integrate_data()
        training_data = integrator.create_training_data(integrated)
        print(f"âœ… ë°ì´í„° í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ: {len(training_data)}í–‰")
        
        # 3. í™˜ê²½ ìƒì„± í…ŒìŠ¤íŠ¸
        print("\nğŸŒ í™˜ê²½ ìƒì„± í…ŒìŠ¤íŠ¸...")
        temp_data_path = current_dir / "temp_test_data.csv"
        training_data.to_csv(temp_data_path, index=False)
        
        env = HedgeEnvironment(
            data_path=str(temp_data_path),
            initial_capital=50000.0,
            max_hedge_ratio=0.5
        )
        print("âœ… í™˜ê²½ ìƒì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        
        # 4. ì—ì´ì „íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        print("\nğŸ¤– ì—ì´ì „íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸...")
        agent = HedgeAgent(
            state_dim=env.observation_space.shape[0],
            action_dim=env.action_space.n,
            learning_rate=1e-3
        )
        print("âœ… ì—ì´ì „íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        
        # 5. ê°„ë‹¨í•œ í•™ìŠµ í…ŒìŠ¤íŠ¸
        print("\nğŸ¯ ê°„ë‹¨í•œ í•™ìŠµ í…ŒìŠ¤íŠ¸...")
        for episode in range(2):
            state, info = env.reset()
            episode_reward = 0
            episode_length = 0
            
            while True:
                action = agent.select_action(state, training=True)
                next_state, reward, done, truncated, info = env.step(action)
                
                state = next_state
                episode_reward += reward
                episode_length += 1
                
                if done or truncated or episode_length >= 5:  # ìµœëŒ€ 5ìŠ¤í…
                    break
            
            print(f"   ì—í”¼ì†Œë“œ {episode + 1}: ë³´ìƒ {episode_reward:.2f}, ê¸¸ì´ {episode_length}")
        
        print("âœ… ê°„ë‹¨í•œ í•™ìŠµ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if temp_data_path.exists():
            temp_data_path.unlink()
        
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='í™˜ ë¦¬ìŠ¤í¬ í—·ì§€ ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸')
    parser.add_argument('--mode', choices=['all', 'data', 'train', 'eval', 'backtest', 'test'], 
                       default='test', help='ì‹¤í–‰ ëª¨ë“œ')
    parser.add_argument('--episodes', type=int, default=1000, help='í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜')
    parser.add_argument('--eval-episodes', type=int, default=100, help='í‰ê°€ ì—í”¼ì†Œë“œ ìˆ˜')
    parser.add_argument('--data-path', type=str, help='ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: ìë™ ìƒì„±)')
    
    args = parser.parse_args()
    
    print("ğŸš€ í™˜ ë¦¬ìŠ¤í¬ í—·ì§€ ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ ì‹œì‘!")
    print(f"ğŸ“‹ ì‹¤í–‰ ëª¨ë“œ: {args.mode}")
    
    # í™˜ê²½ ì„¤ì •
    output_dir, model_dir, integrated_data_dir = setup_environment()
    
    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    if args.data_path:
        data_path = args.data_path
        print(f"ğŸ“ ì‚¬ìš©ì ì§€ì • ë°ì´í„° ê²½ë¡œ: {data_path}")
    else:
        data_path = None
    
    try:
        if args.mode == 'test':
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
            success = run_test()
            if success:
                print("\nâœ… í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                print("ì´ì œ ë‹¤ë¥¸ ëª¨ë“œë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
                print("  python main.py --mode data      # ë°ì´í„° í†µí•©ë§Œ")
                print("  python main.py --mode train     # í•™ìŠµë§Œ")
                print("  python main.py --mode all        # ì „ì²´ íŒŒì´í”„ë¼ì¸")
            else:
                print("\nâŒ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
                return
        
        if args.mode in ['all', 'data']:
            # 1ë‹¨ê³„: ë°ì´í„° í†µí•©
            data_path = run_data_integration()
            if data_path is None:
                print("âŒ ë°ì´í„° í†µí•© ì‹¤íŒ¨ë¡œ ì¸í•´ ì¤‘ë‹¨ë©ë‹ˆë‹¤.")
                return
        
        if args.mode in ['all', 'train']:
            # 2ë‹¨ê³„: ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ í•™ìŠµ
            agent, training_history = run_training(
                data_path, output_dir, model_dir, 
                args.episodes, 100
            )
            if agent is None:
                print("âŒ í•™ìŠµ ì‹¤íŒ¨ë¡œ ì¸í•´ ì¤‘ë‹¨ë©ë‹ˆë‹¤.")
                return
        
        if args.mode in ['all', 'eval'] and 'agent' in locals():
            # 3ë‹¨ê³„: ì—ì´ì „íŠ¸ í‰ê°€
            evaluation_results = run_evaluation(
                agent, data_path, output_dir, args.eval_episodes
            )
        
        if args.mode in ['all', 'backtest'] and 'agent' in locals():
            # 4ë‹¨ê³„: ë°±í…ŒìŠ¤íŒ…
            backtest_results = run_backtesting(agent, data_path, output_dir)
        
        if args.mode != 'test':
            print("\n" + "="*60)
            print("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print("="*60)
            print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤:")
            print(f"   - ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
            print(f"   - ëª¨ë¸ ë””ë ‰í† ë¦¬: {model_dir}")
            print(f"   - í†µí•© ë°ì´í„° ë””ë ‰í† ë¦¬: {integrated_data_dir}")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
