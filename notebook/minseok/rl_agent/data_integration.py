#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
yonju í´ë”ì˜ ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼ì™€ chaewon í´ë”ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í†µí•©
ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ì— í•„ìš”í•œ í†µí•© ë°ì´í„°ì…‹ ìƒì„±
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
import os
import sys
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

class DataIntegrator:
    """ë°ì´í„° í†µí•© í´ë˜ìŠ¤"""
    
    def __init__(self, yonju_data_path: str = None, chaewon_pred_path: str = None):
        """
        Args:
            yonju_data_path: yonju í´ë”ì˜ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            chaewon_pred_path: chaewon í´ë”ì˜ ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
        """
        self.yonju_data_path = yonju_data_path or str(project_root / "notebook" / "yonju" / "df.csv")
        self.chaewon_pred_path = chaewon_pred_path or str(project_root / "notebook" / "chaewon" / "target_trial.csv")
        
        # ë°ì´í„° ì €ì¥ ê²½ë¡œ
        self.output_dir = Path(__file__).parent / "integrated_data"
        self.output_dir.mkdir(exist_ok=True)
        
        print(f"ğŸ“ ë°ì´í„° í†µí•© ì‹œì‘")
        print(f"   yonju ë°ì´í„°: {self.yonju_data_path}")
        print(f"   chaewon ì˜ˆì¸¡: {self.chaewon_pred_path}")
        print(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.output_dir}")
    
    def load_yonju_data(self) -> pd.DataFrame:
        """yonju í´ë”ì˜ ê²½ì œ ë°ì´í„° ë¡œë“œ"""
        try:
            print("ğŸ“Š yonju ë°ì´í„° ë¡œë“œ ì¤‘...")
            df = pd.read_csv(self.yonju_data_path)
            
            # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date').reset_index(drop=True)
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬
            column_mapping = {
                'usdkrw(target)': 'usdkrw(target)',
                'us_ex': 'us_ex',
                'us_im': 'us_im',
                'reserve': 'reserve',
                'us_reserve': 'us_reserve',
                'us_export': 'us_export',
                'us_import': 'us_import',
                'base': 'base',
                'market': 'market',
                'consumer': 'consumer',
                'exp_rate': 'exp_rate',
                'im_rate': 'im_rate',
                'us_gdp': 'us_gdp',
                'us_stock': 'us_stock'
            }
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ì´ë¦„ ë³€ê²½
            available_columns = [col for col in column_mapping.keys() if col in df.columns]
            df = df[['date'] + available_columns].copy()
            
            # ê²°ì¸¡ê°’ ì²˜ë¦¬
            df = df.fillna(method='ffill').fillna(method='bfill')
            
            print(f"âœ… yonju ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰, {len(df.columns)}ì»¬ëŸ¼")
            return df
            
        except Exception as e:
            print(f"âŒ yonju ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self._generate_sample_yonju_data()
    
    def load_chaewon_predictions(self) -> pd.DataFrame:
        """chaewon í´ë”ì˜ ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ"""
        try:
            print("ğŸ”® chaewon ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ ì¤‘...")
            df = pd.read_csv(self.chaewon_pred_path)
            
            # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date').reset_index(drop=True)
            
            # ì˜ˆì¸¡ê°’ ì»¬ëŸ¼ í™•ì¸ ë° ì²˜ë¦¬
            if 'usdkrw(target)' in df.columns:
                df = df[['date', 'usdkrw(target)']].copy()
                df.columns = ['date', 'predicted_usekrw']
            elif 'predicted_usekrw' in df.columns:
                df = df[['date', 'predicted_usekrw']].copy()
            else:
                # ì˜ˆì¸¡ê°’ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ìƒì„±
                df['predicted_usekrw'] = df.iloc[:, 1] if len(df.columns) > 1 else 1300
            
            print(f"âœ… chaewon ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰")
            return df
            
        except Exception as e:
            print(f"âŒ chaewon ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self._generate_sample_chaewon_data()
    
    def _generate_sample_yonju_data(self) -> pd.DataFrame:
        """ìƒ˜í”Œ yonju ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)"""
        print("ğŸ“Š ìƒ˜í”Œ yonju ë°ì´í„° ìƒì„± ì¤‘...")
        
        # 2023-01-01ë¶€í„° 2024-12-31ê¹Œì§€ì˜ ì¼ë³„ ë°ì´í„°
        dates = pd.date_range('2023-01-01', '2024-12-31', freq='D')
        n_days = len(dates)
        
        np.random.seed(42)
        
        # USD/KRW í™˜ìœ¨ (ì‹¤ì œì™€ ìœ ì‚¬í•œ íŒ¨í„´)
        usdkrw_base = 1300
        usdkrw_trend = np.cumsum(np.random.normal(0, 0.3, n_days))
        usdkrw = usdkrw_base + usdkrw_trend + np.random.normal(0, 8, n_days)
        
        # ê¸°íƒ€ ê²½ì œ ì§€í‘œë“¤ (ì •ê·œí™”ëœ ê°’)
        data = {
            'date': dates,
            'usdkrw(target)': usdkrw,
            'us_ex': np.random.normal(0, 1, n_days),
            'us_im': np.random.normal(0, 1, n_days),
            'reserve': np.random.normal(0, 1, n_days),
            'us_reserve': np.random.normal(0, 1, n_days),
            'us_export': np.random.normal(0, 1, n_days),
            'us_import': np.random.normal(0, 1, n_days),
            'base': np.random.normal(0, 1, n_days),
            'market': np.random.normal(0, 1, n_days),
            'consumer': np.random.normal(0, 1, n_days),
            'exp_rate': np.random.normal(0, 1, n_days),
            'im_rate': np.random.normal(0, 1, n_days),
            'us_gdp': np.random.normal(0, 1, n_days),
            'us_stock': np.random.normal(0, 1, n_days)
        }
        
        df = pd.DataFrame(data)
        print("âœ… ìƒ˜í”Œ yonju ë°ì´í„° ìƒì„± ì™„ë£Œ")
        return df
    
    def _generate_sample_chaewon_data(self) -> pd.DataFrame:
        """ìƒ˜í”Œ chaewon ì˜ˆì¸¡ ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)"""
        print("ğŸ”® ìƒ˜í”Œ chaewon ì˜ˆì¸¡ ë°ì´í„° ìƒì„± ì¤‘...")
        
        # 2025-01-01ë¶€í„° 2025-01-31ê¹Œì§€ì˜ ì¼ë³„ ì˜ˆì¸¡ ë°ì´í„°
        dates = pd.date_range('2025-01-01', '2025-01-31', freq='D')
        n_days = len(dates)
        
        np.random.seed(42)
        
        # ì˜ˆì¸¡ëœ USD/KRW í™˜ìœ¨
        predicted_base = 1320  # 2024ë…„ ë§ ëŒ€ë¹„ ì•½ê°„ ìƒìŠ¹
        predicted_trend = np.cumsum(np.random.normal(0, 0.2, n_days))
        predicted_usekrw = predicted_base + predicted_trend + np.random.normal(0, 5, n_days)
        
        data = {
            'date': dates,
            'predicted_usekrw': predicted_usekrw
        }
        
        df = pd.DataFrame(data)
        print("âœ… ìƒ˜í”Œ chaewon ì˜ˆì¸¡ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        return df
    
    def integrate_data(self) -> pd.DataFrame:
        """ë°ì´í„° í†µí•©"""
        print("ğŸ”— ë°ì´í„° í†µí•© ì¤‘...")
        
        # ë°ì´í„° ë¡œë“œ
        yonju_df = self.load_yonju_data()
        chaewon_df = self.load_chaewon_predictions()
        
        # ë‚ ì§œ ë²”ìœ„ í™•ì¸
        yonju_start = yonju_df['date'].min()
        yonju_end = yonju_df['date'].max()
        chaewon_start = chaewon_df['date'].min()
        chaewon_end = chaewon_df['date'].max()
        
        print(f"ğŸ“… yonju ë°ì´í„° ê¸°ê°„: {yonju_start.date()} ~ {yonju_end.date()}")
        print(f"ğŸ“… chaewon ì˜ˆì¸¡ ê¸°ê°„: {chaewon_start.date()} ~ {chaewon_end.date()}")
        
        # ë°ì´í„° í†µí•©
        # 1. yonju ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í†µí•©
        integrated_df = yonju_df.copy()
        
        # 2. chaewon ì˜ˆì¸¡ ë°ì´í„° ì¶”ê°€
        integrated_df = pd.merge(integrated_df, chaewon_df, on='date', how='left')
        
        # 3. ì˜ˆì¸¡ê°’ì´ ì—†ëŠ” ê¸°ê°„ì€ ì‹¤ì œê°’ìœ¼ë¡œ ì±„ì›€
        integrated_df['predicted_usekrw'] = integrated_df['predicted_usekrw'].fillna(integrated_df['usdkrw(target)'])
        
        # 4. ë‚ ì§œìˆœ ì •ë ¬
        integrated_df = integrated_df.sort_values('date').reset_index(drop=True)
        
        # 5. ê²°ì¸¡ê°’ ì²˜ë¦¬
        integrated_df = integrated_df.fillna(method='ffill').fillna(method='bfill')
        
        print(f"âœ… ë°ì´í„° í†µí•© ì™„ë£Œ: {len(integrated_df)}í–‰, {len(integrated_df.columns)}ì»¬ëŸ¼")
        
        return integrated_df
    
    def create_training_data(self, integrated_df: pd.DataFrame) -> pd.DataFrame:
        """ê°•í™”í•™ìŠµìš© í›ˆë ¨ ë°ì´í„° ìƒì„±"""
        print("ğŸ¯ ê°•í™”í•™ìŠµìš© í›ˆë ¨ ë°ì´í„° ìƒì„± ì¤‘...")
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        required_columns = [
            'date', 'usdkrw(target)', 'predicted_usekrw',
            'us_ex', 'us_im', 'reserve', 'us_reserve',
            'us_export', 'us_import', 'base', 'market',
            'consumer', 'exp_rate', 'im_rate', 'us_gdp', 'us_stock'
        ]
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_columns = [col for col in required_columns if col in integrated_df.columns]
        training_df = integrated_df[available_columns].copy()
        
        # ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
        print(f"ğŸ“Š ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬:")
        print(f"   ì „ì²´ í–‰ ìˆ˜: {len(training_df)}")
        print(f"   ê²°ì¸¡ê°’ ê°œìˆ˜: {training_df.isnull().sum().sum()}")
        print(f"   ì¤‘ë³µ í–‰ ìˆ˜: {training_df.duplicated().sum()}")
        
        # ê²°ì¸¡ê°’ì´ ìˆëŠ” í–‰ ì œê±°
        training_df = training_df.dropna()
        print(f"   ê²°ì¸¡ê°’ ì œê±° í›„ í–‰ ìˆ˜: {len(training_df)}")
        
        # ë‚ ì§œ ë²”ìœ„ í™•ì¸
        date_range = training_df['date'].max() - training_df['date'].min()
        print(f"   ë°ì´í„° ê¸°ê°„: {date_range.days}ì¼")
        
        return training_df
    
    def save_integrated_data(self, df: pd.DataFrame, filename: str = "integrated_hedge_data.csv") -> str:
        """í†µí•©ëœ ë°ì´í„° ì €ì¥"""
        output_path = self.output_dir / filename
        
        # CSVë¡œ ì €ì¥
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ í†µí•© ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_path}")
        
        # ë°ì´í„° ìš”ì•½ ì •ë³´ ì €ì¥
        summary_path = self.output_dir / "data_summary.txt"
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("=== í™˜ ë¦¬ìŠ¤í¬ í—·ì§€ ê°•í™”í•™ìŠµ ë°ì´í„° ìš”ì•½ ===\n\n")
            f.write(f"ë°ì´í„° ê¸°ê°„: {df['date'].min().date()} ~ {df['date'].max().date()}\n")
            f.write(f"ì „ì²´ í–‰ ìˆ˜: {len(df):,}\n")
            f.write(f"ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}\n")
            f.write(f"ì»¬ëŸ¼ ëª©ë¡: {', '.join(df.columns)}\n\n")
            
            f.write("=== ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ í†µê³„ ===\n")
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                if col != 'date':
                    f.write(f"{col}:\n")
                    f.write(f"  í‰ê· : {df[col].mean():.4f}\n")
                    f.write(f"  í‘œì¤€í¸ì°¨: {df[col].std():.4f}\n")
                    f.write(f"  ìµœì†Œê°’: {df[col].min():.4f}\n")
                    f.write(f"  ìµœëŒ€ê°’: {df[col].max():.4f}\n\n")
        
        print(f"ğŸ“‹ ë°ì´í„° ìš”ì•½ ì €ì¥ ì™„ë£Œ: {summary_path}")
        
        return str(output_path)
    
    def run_integration(self) -> str:
        """ì „ì²´ ë°ì´í„° í†µí•© í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸš€ ë°ì´í„° í†µí•© í”„ë¡œì„¸ìŠ¤ ì‹œì‘\n")
        
        # 1. ë°ì´í„° í†µí•©
        integrated_df = self.integrate_data()
        
        # 2. í›ˆë ¨ ë°ì´í„° ìƒì„±
        training_df = self.create_training_data(integrated_df)
        
        # 3. ê²°ê³¼ ì €ì¥
        output_path = self.save_integrated_data(training_df)
        
        print(f"\nğŸ‰ ë°ì´í„° í†µí•© ì™„ë£Œ!")
        print(f"   ìµœì¢… ë°ì´í„° ê²½ë¡œ: {output_path}")
        print(f"   ë°ì´í„° í¬ê¸°: {len(training_df):,}í–‰ Ã— {len(training_df.columns)}ì»¬ëŸ¼")
        
        return output_path

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ë°ì´í„° í†µí•©ê¸° ìƒì„±
    integrator = DataIntegrator()
    
    # ë°ì´í„° í†µí•© ì‹¤í–‰
    output_path = integrator.run_integration()
    
    print(f"\nâœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"   í†µí•©ëœ ë°ì´í„°: {output_path}")
    print(f"   ì´ì œ ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ í•™ìŠµì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
